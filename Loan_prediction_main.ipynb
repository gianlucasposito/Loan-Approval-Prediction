{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35c269cc-1ca7-4c05-b27e-4e5c277628cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import library\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.set_option('future.no_silent_downcasting', True)\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, cross_val_score, GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from xgboost import XGBClassifier\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4eda532-4593-4bda-8239-eebdea0d0316",
   "metadata": {},
   "source": [
    "## Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5a04627-1e01-4517-a433-09d00a8e38e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the datasets\n",
    "train_data = pd.read_csv('Data/Loan_dataset_train.csv') # This is the portion of the dataset used to \"train\" or fit the model.\n",
    "test_data = pd.read_csv('Data/Loan_dataset_test.csv') # This subset is reserved for evaluating the model’s performance after training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82a61398-1a4e-4a56-8386-c3f30f92a8eb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Display the first few rows of the training dataset\n",
    "print(\"Training Data Head:\")\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eca59fc8-940d-4e78-9deb-106a2e7e90b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Display the first few rows of the test dataset\n",
    "print(\"\\nTest Data Head:\")\n",
    "test_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdbae21f-64ca-4560-a606-240640872501",
   "metadata": {},
   "source": [
    "## Understanding the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f831a066-e44b-4b0d-bca5-927d361f2d0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data columns\n",
    "train_data.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f4fda37-e997-4366-a00f-d600986bdaf2",
   "metadata": {},
   "source": [
    "There are 12 independent variables and 1 target variable, i.e., `Loan_Status`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68f3b76c-7f60-49cd-a8c8-46799817be70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data columns\n",
    "test_data.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "414be230-4cd5-446f-8974-a906d6c7f534",
   "metadata": {},
   "source": [
    "The test dataset contains the same features as the training dataset, except for `Loan_Status`. The model will be trained on the training data to predict `Loan_Status` for the test dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "377156b0-b541-4602-99e1-d6eb8b13b227",
   "metadata": {},
   "source": [
    "The description of each variable is provided below.\n",
    "\n",
    "| Variable           | Description                                  |\r\n",
    "|--------------------|----------------------------------------------|\r\n",
    "| Loan_ID            | Unique Loan ID                               |\r\n",
    "| Gender             | Male/ Female                                 |\r\n",
    "| Married            | Applicant married (Y/N)                      |\r\n",
    "| Dependents         | Number of dependents                         |\r\n",
    "| Education          | Applicant Education (Graduate/Under Graduate)|\r\n",
    "| Self_Employed      | Self employed (Y/N)                          |\r\n",
    "| ApplicantIncome    | Applicant income                             |\r\n",
    "| CoapplicantIncome  | Coapplicant income                           |\r\n",
    "| LoanAmount         | Loan amount in thousands                     |\r\n",
    "| Loan_Amount_Term   | Term of loan in months                       |\r\n",
    "| Credit_History     | Creof individual’s repayment of their debts guidelines              |\r\n",
    "| Property_Area      | Urban/ Semi Urban/ Rural                     |\r\n",
    "| Loan_Status        | Loan approved (Y/N)                          |\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba47aec3-22d7-494c-8805-4830ec7b40a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset shape\n",
    "train_data.shape, test_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "323585b5-8595-4997-9a50-f98e474bfee6",
   "metadata": {},
   "source": [
    "The training dataset contains 614 rows and 13 columns, while the test dataset includes 367 rows and 12 columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ef2ca73-f0c3-4479-ad9f-f69c8d70ae80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove the Loan_ID variable since it doesn't impact the loan status. \n",
    "\n",
    "train_data = train_data.drop('Loan_ID', axis=1)\n",
    "test_data = test_data.drop('Loan_ID', axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08e89402-9562-4c57-8091-d5b5f4cdc88b",
   "metadata": {},
   "source": [
    "## Feature Engineering\n",
    "\n",
    "To enhance our model's predictive power, new features are introduced based on our domain knowledge (for more details see this conference [paper](https://doi.org/10.1051/itmconf/20224403019)). These features are designed to influence the target variable, loan approval likelihood, as follows:\n",
    "\n",
    "1. **Total Income**  \n",
    "   - By combining the `Applicant Income` and `Co-applicant Income`, we create a `Total Income` feature. Higher total income may correlate with a higher probability of loan approval, as it indicates greater financial capability. \n",
    "\n",
    "2. **EMI (Equated Monthly Installment)**  \n",
    "   - EMI represents the fixed monthly payment required to repay the loan over the specified term. EMI is the ratio of the loan amount to the loan term. Applicants with a high EMI might experience more financial strain, potentially lowering their ability to keep up with payments.\n",
    "\n",
    "3. **Balance Income**  \n",
    "   - This feature captures the income remaining after the EMI has been deducted. We hypothesize that a higher balance income enhances the likelihood of loan repayment, as it suggests sufficient funds are available even after covering loan payments, increasing the chances of loan approval."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63fd5cde-9364-4508-be0c-4d47ed4de809",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Total Income\n",
    "train_data['Total_Income']=train_data['ApplicantIncome']+train_data['CoapplicantIncome']\n",
    "test_data['Total_Income']=test_data['ApplicantIncome']+test_data['CoapplicantIncome']\n",
    "\n",
    "# EMI\n",
    "train_data['EMI']=train_data['LoanAmount']/train_data['Loan_Amount_Term'] \n",
    "test_data['EMI']=test_data['LoanAmount']/test_data['Loan_Amount_Term']\n",
    "\n",
    "# Balance Income\n",
    "train_data['Balance_Income']=train_data['Total_Income']-(train_data['EMI']*1000) \n",
    "test_data['Balance_Income']=test_data['Total_Income']-(test_data['EMI']*1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aee2f327-74fe-484b-8dcd-1f18fda5437f",
   "metadata": {},
   "source": [
    "Remove the variables used to create these new features, as they will likely be highly correlated with the new features. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aac18527-cdb1-45c3-9116-ed9cdc1d5dcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data=train_data.drop(['ApplicantIncome', 'CoapplicantIncome', 'LoanAmount', 'Loan_Amount_Term'], axis=1)\n",
    "test_data=test_data.drop(['ApplicantIncome', 'CoapplicantIncome', 'LoanAmount', 'Loan_Amount_Term'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e980592-6d74-49f6-978a-430e8cd66cac",
   "metadata": {},
   "source": [
    "## Data Exploration\n",
    "Expanding on the exploratory analysis will allow to better understand the data distribution, feature relationships, and key patterns."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bb11b19-2fb3-4521-ae7e-4b4569eda201",
   "metadata": {},
   "source": [
    "### Univariate analysis\n",
    "This part focuses on examining each feature individually, understanding the distribution of categorical and numerical variables, and identifying potential outliers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d644b592-776b-4c32-ac83-f71a2bde34e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bar chart and pie chart\n",
    "fig, axes = plt.subplots(1, 2, figsize=(8, 4))\n",
    "\n",
    "# Bar chart for 'Loan_Status' distribution\n",
    "\n",
    "# Counting the values for 'Loan_Status'\n",
    "loan_status_counts = train_data['Loan_Status'].value_counts()\n",
    "# Calculating percentages for pie chart\n",
    "total = loan_status_counts.sum()\n",
    "loan_status_percentages = (loan_status_counts / total) * 100\n",
    "\n",
    "loan_status_counts.plot.bar(ax=axes[0], color=['skyblue', 'lightcoral'], edgecolor='black')\n",
    "axes[0].set_title('Distribution of Loan Status (Y/N) - Bar Chart')\n",
    "axes[0].set_xlabel('Loan Status')\n",
    "axes[0].set_ylabel('Count')\n",
    "\n",
    "# Pie chart for 'Loan_Status' distribution\n",
    "axes[1].pie(loan_status_percentages, labels=loan_status_counts.index, autopct='%1.1f%%', startangle=90, \n",
    "            colors=['skyblue', 'lightcoral'], wedgeprops={'edgecolor': 'black'})\n",
    "axes[1].set_title('Distribution of Loan Status (Y/N) - Pie Chart')\n",
    "\n",
    "# Displaying the combined plot\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "872e8fe5-3830-4956-b90c-d4d209969f88",
   "metadata": {},
   "source": [
    "The distribution plot shows that the target variable, `Loan_Status`, has more approved loans (labeled as Y) than disapproved ones (labeled as N). 68.7% had received loan approval, while 31.3% were rejected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24036419-91c8-4385-b1f3-92009b18d641",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distributions of numerical features\n",
    "\n",
    "# List of numerical columns\n",
    "numerical_columns = ['ApplicantIncome', 'CoapplicantIncome', 'LoanAmount'] \n",
    "\n",
    "# Loop through each column to create distribution and boxplots\n",
    "for column in numerical_columns:\n",
    "    plt.figure(figsize=(16, 5))\n",
    "    \n",
    "    # Distribution plot\n",
    "    plt.subplot(1, 2, 1)\n",
    "    sns.histplot(train_data[column], kde=True)  \n",
    "    plt.title(f'Distribution of {column}')\n",
    "    \n",
    "    # Boxplot\n",
    "    plt.subplot(1, 2, 2)\n",
    "    train_data[column].plot.box()\n",
    "    plt.title(f'Boxplot of {column}')\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07d0a92b-6c1b-4106-a789-595b62f457d9",
   "metadata": {},
   "source": [
    "The histograms show that the distribution of `ApplicantIncome` and `CoapplicantIncome` are right-skewed, indicating that a few applicants have significantly higher incomes than others. This skewness might necessitate scaling or transformation for more effective modeling. \n",
    "Additionally, `LoanAmount` also exhibits a similar right-skewed distribution.\n",
    "There are also some outliers that will be addressed in later sections."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f07fc1b0-5cd6-4495-a82f-829d4e02f08b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distributions of categorical features\n",
    "\n",
    "# List of categorical columns\n",
    "categorical_features = ['Gender', 'Married', 'Dependents', 'Education', 'Self_Employed', 'Property_Area', 'Loan_Amount_Term', 'Credit_History']\n",
    "\n",
    "# Plot through each column\n",
    "plt.figure(figsize=(15, 10))\n",
    "for i, column in enumerate(categorical_features, 1):\n",
    "    plt.subplot(3, 3, i)\n",
    "    sns.countplot(data=train_data, x=column)\n",
    "    plt.title(f'Distribution of {column}')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b9880d1-dded-43c3-a31e-17794f99d020",
   "metadata": {},
   "source": [
    "The count plots reveal key characteristics of the categorical features:\n",
    "\n",
    "- `Gender` and `Married`: The majority of applicants are male and married.\n",
    "- `Dependents`: There is a higher proportion of applicants without dependents, with fewer applicants reporting multiple dependents.\n",
    "- `Education`: Most applicants are graduates.\n",
    "- `Self_Employed`: Fewer applicants are self-employed, which might be a distinguishing characteristic among applicants.\n",
    "- `Credit_History`: The majority of applicants have repaid their debts\n",
    "- `Property_Area`: The distribution is fairly balanced across *Rural*, *Urban*, and *Semiurban* areas, potentially aiding in differentiating loan outcomes based on geographic context."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4878567a-80bf-4542-9d23-bfc1fd176968",
   "metadata": {},
   "source": [
    "### Bivariate Analysis\n",
    "\n",
    "Bivariate analysis explores the relationship between each feature and the target variable, allowing to examine potential correlations or patterns.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8978bf2-4c8b-4ee1-8906-8725583dd38a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Countplots for categorical features with respect to target\n",
    "plt.figure(figsize=(15, 10))\n",
    "for i, column in enumerate(categorical_features, 1):\n",
    "    plt.subplot(3, 3, i)\n",
    "    sns.countplot(data=train_data, x=column, hue='Loan_Status')  \n",
    "    plt.title(f'{column} vs Target')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b952f5ff-2d69-4aa2-b25e-cfb3ecf64602",
   "metadata": {},
   "source": [
    "The count plots for categorical features reveal key relationships with loan approval status (`Loan_Status`). Here’s a summary of the insights:\n",
    "\n",
    "- Male and married applicants have slightly higher loan approval rates, though this difference is minor.\n",
    "- Applicants with fewer dependents appear to have slightly better approval rates.\n",
    "- Graduates show higher loan approval rates than non-graduates.\n",
    "- Non-self-employed applicants have higher approval rates.\n",
    "- Applicants with a credit history (recorded as 1.0) show a significantly higher loan approval rate, indicating it is a strong predictor.\n",
    "- Approval rates are higher in *Semiurban* areas compared to *Urban* and *Rural* areas. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3e23d14-d2d7-4b8e-821a-fd460214c52b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Boxplots to analyze numerical features against the target variable\n",
    "\n",
    "plt.figure(figsize=(15, 10))\n",
    "for i, column in enumerate(numerical_columns, 1):\n",
    "    plt.subplot(3, 3, i)\n",
    "    sns.boxplot(data=train_data, x='Loan_Status', y=column)  \n",
    "    plt.title(f'{column} vs Target')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25197fae-b0e4-4965-85a4-ea5f8af79cd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to remove outliers based on IQR\n",
    "def remove_outliers(df, column):\n",
    "    Q1 = df[column].quantile(0.25)\n",
    "    Q3 = df[column].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    lower_bound = Q1 - 1.5 * IQR\n",
    "    upper_bound = Q3 + 1.5 * IQR\n",
    "    return df[(df[column] >= lower_bound) & (df[column] <= upper_bound)]\n",
    "\n",
    "# Remove outliers for each numerical column\n",
    "filtered_data = train_data.copy()\n",
    "for column in numerical_columns:\n",
    "    filtered_data = remove_outliers(filtered_data, column)\n",
    "\n",
    "# Plot boxplots without outliers\n",
    "plt.figure(figsize=(15, 10))\n",
    "for i, column in enumerate(numerical_columns, 1):\n",
    "    plt.subplot(3, 3, i)\n",
    "    sns.boxplot(data=filtered_data, x='Loan_Status', y=column)  \n",
    "    plt.title(f'{column} vs Target')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17d623c9-ec7b-4a03-a972-720333ecf86b",
   "metadata": {},
   "source": [
    "The boxplots for numerical features provide insight into their relationship with loan approval status (`Loan_Status`). Here is a summary of the observed patterns:\n",
    "\n",
    "- Approved and not approved loans for `ApplicantIncome` and `CoapplicantIncome` have similar distributions, though some outliers exist for higher incomes.\n",
    "- Higher `LoanAmount` values appear in both approved and unapproved loans but with more variability in the not approved group, potentially hinting at an influencing factor.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d405c1c7-25c5-4c30-be8b-fbb0bd90267b",
   "metadata": {},
   "source": [
    "### Correlation Analysis\n",
    "\n",
    "Correlation analysis considers the interactions between multiple variables, which can uncover deeper insights about the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16c49646-a73d-4bda-b8ab-eb912caaae35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation matrix for numerical features\n",
    "\n",
    "#  Prepare data for correlation analysis\n",
    "train_data['Loan_Status'] = train_data['Loan_Status'].replace({'Y': 1, 'N': 0})\n",
    "\n",
    "train_data['Gender'] = train_data['Gender'].replace({'Male': 1, 'Female': 0})\n",
    "test_data['Gender'] = test_data['Gender'].replace({'Male': 1, 'Female': 0})\n",
    "\n",
    "train_data['Married'] = train_data['Married'].replace({'Yes': 1, 'No': 0})\n",
    "test_data['Married'] = test_data['Married'].replace({'Yes': 1, 'No': 0})\n",
    "\n",
    "train_data['Self_Employed'] = train_data['Self_Employed'].replace({'Yes': 1, 'No': 0})\n",
    "test_data['Self_Employed'] = test_data['Self_Employed'].replace({'Yes': 1, 'No': 0})\n",
    "\n",
    "# Property_Area, Dependents, Education has multiple values\n",
    "encode_columns = ['Property_Area', 'Dependents', 'Education']\n",
    "le = LabelEncoder()\n",
    "for col in encode_columns:\n",
    "    train_data[col] = le.fit_transform(train_data[col])\n",
    "    test_data[col] = le.transform(test_data[col])\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(train_data.corr(), annot=True, cmap='coolwarm', fmt='.2f')\n",
    "plt.title('Correlation Matrix of Numerical Features')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbfcc360-fd0f-452a-bb3d-b2af9605f27f",
   "metadata": {},
   "source": [
    "\r\n",
    "The correlation matrix provides insights into the relationships between various numerical features in the dataset with a focus on predicting the `Loan_Status`. Here are the key observations:\r\n",
    "\r\n",
    "1. **Loan Status Correlations**:\r\n",
    "   - `Credit_History` shows the highest positive correlation with `Loan_Status` (0.56), suggesting that credit history is a significant factor in determining loan approval.\r\n",
    "   - `Married` has a slight positive correlation (0.09) with `Loan_Status`, but this relationship is weak and may not be particularly influential in predictions.\r\n",
    "   - Other features like `ApplicantIncome`, `CoapplicantIncome`, and `LoanAmount` have very minimal correlations with `Loan_Status`, indicating they might have a limited direct impact.\r\n",
    "\r\n",
    "2. **Feature Interdependencies**:\r\n",
    "   - `ApplicantIncome` and `LoanAmount` have a moderately positive correlation (0.57), which makes sense as higher incomes often allow for larger loan amounts.\r\n",
    "   - `LoanAmount` also has a weak positive correlation with `CoapplicantIncome` (0.19), showing some connection but not as strong as with `ApplicantIncome`.\r\n",
    "   - `Married` and `Dependents` have a positive correlation (0.31), which aligns with the likelihood of having more dependents after marriage.\r\n",
    "\r\n",
    "3. **Negligible Correlations**:\r\n",
    "   - Many features, such as `Gender`, `Education`, `Self_Employed`, and `Property_Area`, exhibit very low or near-zero correlations with `Loan_Status`, suggesting that these factors may not play a crucial role in predicting loan approval.\r\n",
    "   - `Loan_Amount_Term` and most other features have near-zero correlations with each other, showing minimal interdependencies.\r\n",
    "\r\n",
    "4. **Insights for Predictive Modeling**:\r\n",
    "   - Given the high correlation between `Credit_History` and `Loan_Status`, `Credit_History` should be a primary feature in the model.\r\n",
    "   - Other features with minimal correlation may not significantly contribute to predicting `Loan_Status` and could be reconsidered during feature selection to snr larger loan amounts.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e555643-2304-469e-a34d-f007bbdffe61",
   "metadata": {},
   "source": [
    "## Missing Value and Outlier Treatment\r\n",
    "Identifying missing values and outliers aims to improve data quality by ensuring accuracy and reliability, as these issues can skew analysis and lead to incorrect conclusions. Addressing them helps build robust models and derive meaningful insights from the data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ddac53d-c242-4f82-987e-2a0911af7515",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values\n",
    "train_data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9dceb3a-db22-4eb7-9d07-3da68f54a003",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values\n",
    "test_data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23694498-f806-4533-bf94-287d3122c176",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill or drop missing values as necessary\n",
    "# For example, filling categorical missing values with the mode and numerical with the median\n",
    "for column in train_data.columns:\n",
    "    if column in  categorical_features:\n",
    "        train_data[column] = train_data[column].fillna(train_data[column].mode()[0])\n",
    "        test_data[column] = train_data[column].fillna(train_data[column].mode()[0])\n",
    "    else:\n",
    "        train_data[column] = train_data[column].fillna(train_data[column].median())\n",
    "        test_data[column] = train_data[column].fillna(train_data[column].median())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63f6f3de-a495-4e22-b856-0fcc1f4edb13",
   "metadata": {},
   "source": [
    "Apply the log transformation to right-skewed column distributions: smaller values are only minimally impacted, while larger values are substantially reduced, resulting in a distribution that more closely resembles a normal distribution. This transformation mitigates the influence of extreme values, making the distribution more symmetric and suitable for modeling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eb9faa9-a8fe-4761-adef-85efc8e44018",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loan Amount\n",
    "train_data['LoanAmount_log'] = np.log(train_data['LoanAmount']) \n",
    "train_data['LoanAmount_log'].hist(bins=20) # effect of log transformation\n",
    "test_data['LoanAmount_log'] = np.log(test_data['LoanAmount'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9c2799d-dad9-4b04-9fd0-b0d7c7d05c8a",
   "metadata": {},
   "source": [
    "`ApplicantIncome` and `CoapplicantIncome` include zero values. Since a log transformation requires positive values, a small constant can be added to shift the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "819c2ddc-b56e-46cf-b951-3a02ee9304b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ApplicantIncome\n",
    "c = 1\n",
    "train_data['ApplicantIncome_log'] = np.log(train_data['ApplicantIncome'] + c) \n",
    "train_data['ApplicantIncome_log'].hist(bins=20) # effect of log transformation\n",
    "test_data['ApplicantIncome_log'] = np.log(test_data['ApplicantIncome'] + c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00d3d7c4-71c7-4602-a692-c283491ee117",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CoapplicantIncome\n",
    "train_data['CoapplicantIncome_log'] = np.log(train_data['CoapplicantIncome'] + c) \n",
    "train_data['CoapplicantIncome_log'].hist(bins=20) # effect of log transformation\n",
    "test_data['CoapplicantIncome_log'] = np.log(test_data['CoapplicantIncome'] + c)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91f2c70c-48c0-495c-b340-5ba3db360786",
   "metadata": {},
   "source": [
    "## Machine Learning Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "155dd5d9-76b5-4654-a6ed-c4ecdf0879ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data for feeding into the model\n",
    "X = train_data.drop('Loan_Status', axis=1) \n",
    "y = train_data.Loan_Status.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a67ae8fb-12cb-49c1-9e8e-6a0fe666a69c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the logistic regression model as a basaline method\n",
    "LR_model = LogisticRegression(max_iter=1000)\n",
    "\n",
    "# Define 10-fold stratified cross-validator\n",
    "skf = StratifiedKFold(n_splits=10, shuffle=True, random_state=27)\n",
    "\n",
    "# Perform cross-validation and collect accuracy for each fold\n",
    "accuracies = cross_val_score(LR_model, X, y, cv=skf, scoring='accuracy')\n",
    "\n",
    "# Print mean and standard deviation of accuracy\n",
    "print(f\"\\nMean Accuracy: {accuracies.mean():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e9c2bbe-64a3-4ef0-aab3-f96a3963d544",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Advanced methods to improve accuracy\n",
    "\n",
    "# Support Vector Machine (SVM)\n",
    "svm_params = {\n",
    "    'C': [0.1, 1, 10, 100],\n",
    "    'kernel': ['linear', 'rbf'],\n",
    "    'gamma': ['scale', 'auto']\n",
    "}\n",
    "svm_model = SVC()\n",
    "svm_grid = GridSearchCV(svm_model, svm_params, cv=skf, scoring='accuracy')\n",
    "svm_grid.fit(X, y)\n",
    "print(\"Best SVM Parameters:\", svm_grid.best_params_)\n",
    "print(\"Best SVM Accuracy:\", svm_grid.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6f934a9-d595-415d-9cfc-855c2d75db55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest\n",
    "rf_params = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'max_depth': [None, 10, 20, 30],\n",
    "    'min_samples_split': [2, 5, 10]\n",
    "}\n",
    "rf_model = RandomForestClassifier(random_state=42)\n",
    "rf_grid = GridSearchCV(rf_model, rf_params, cv=skf, scoring='accuracy')\n",
    "rf_grid.fit(X, y)\n",
    "print(\"Best Random Forest Parameters:\", rf_grid.best_params_)\n",
    "print(\"Best Random Forest Accuracy:\", rf_grid.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1efe6ff3-e0d5-4a26-9997-daea42b9458c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# XGBoost\n",
    "xgb_params = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'learning_rate': [0.01, 0.1, 0.2],\n",
    "    'max_depth': [3, 6, 10]\n",
    "}\n",
    "xgb_model = XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=42)\n",
    "xgb_grid = GridSearchCV(xgb_model, xgb_params, cv=skf, scoring='accuracy')\n",
    "xgb_grid.fit(X, y)\n",
    "print(\"Best XGBoost Parameters:\", xgb_grid.best_params_)\n",
    "print(\"Best XGBoost Accuracy:\", xgb_grid.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f430afd1-379c-43a6-801f-ed6e9f50f048",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Plot feature importances for Random Forest\n",
    "def plot_rf_feature_importance(model, feature_names):\n",
    "    importances = model.feature_importances_\n",
    "    indices = np.argsort(importances)[::-1]\n",
    "    \n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.title(\"Random Forest Feature Importances\")\n",
    "    plt.bar(range(len(importances)), importances[indices], align=\"center\")\n",
    "    plt.xticks(range(len(importances)), [feature_names[i] for i in indices], rotation=90)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Plot feature importances for XGBoost\n",
    "def plot_xgb_feature_importance(model, feature_names):\n",
    "    importances = model.feature_importances_\n",
    "    indices = np.argsort(importances)[::-1]\n",
    "    \n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.title(\"XGBoost Feature Importances\")\n",
    "    plt.bar(range(len(importances)), importances[indices], align=\"center\")\n",
    "    plt.xticks(range(len(importances)), [feature_names[i] for i in indices], rotation=90)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Retrieve and plot feature importances for the best Random Forest model\n",
    "best_rf_model = rf_grid.best_estimator_\n",
    "feature_names = [f\"Feature {i}\" for i in range(X.shape[1])]  # Assumes generic feature names; replace as necessary\n",
    "plot_rf_feature_importance(best_rf_model, feature_names)\n",
    "\n",
    "# Retrieve and plot feature importances for the best XGBoost model\n",
    "best_xgb_model = xgb_grid.best_estimator_\n",
    "plot_xgb_feature_importance(best_xgb_model, feature_names)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
